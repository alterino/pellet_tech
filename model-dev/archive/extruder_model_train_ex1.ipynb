{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_columns_by_frequency(\n",
    "    df, columns, \n",
    "    freq='D', \n",
    "    ignore_datetimes=False, \n",
    "    vertical_lines=None,\n",
    "    line_text=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot columns from a dataframe based on specified frequency.\n",
    "    \n",
    "    df: pandas DataFrame with a datetime index\n",
    "    columns: list of columns to plot\n",
    "    freq: frequency for plotting ('D' for day, 'W' for week, 'M' for month, 'Y' for year, or integer if ignore_datetimes=True)\n",
    "    ignore_datetimes: if True, plots against a dummy index instead of datetimes\n",
    "    vertical_lines: list of 2-tuple with datetimes indicating positions for vertical lines. \n",
    "                    The first datetime is plotted as a red line and the second as a green line.\n",
    "    \"\"\"\n",
    "\n",
    "    if ignore_datetimes:\n",
    "        if isinstance(freq, int):\n",
    "            num_points = freq\n",
    "        else:\n",
    "            raise ValueError(\"When ignore_datetimes=True, freq should be an integer representing number of points.\")\n",
    "        \n",
    "        indices = list(range(0, len(df), num_points))\n",
    "        if indices[-1] != len(df):\n",
    "            indices.append(len(df))\n",
    "\n",
    "        for start, end in zip(indices[:-1], indices[1:]):\n",
    "            subset = df.iloc[start:end]\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            subset[columns].plot(ax=plt.gca(), marker='.', linestyle='--', secondary_y=True)\n",
    "            \n",
    "            if vertical_lines:\n",
    "                for line in vertical_lines:\n",
    "                    if df.index[start] <= line[0] <= df.index[end-1]:\n",
    "                        idx_before = df.index.get_loc(line[0], method='ffill')\n",
    "                        idx_after = df.index.get_loc(line[0], method='bfill')\n",
    "                        pos = (idx_before + idx_after) / 2 - start\n",
    "                        plt.axvline(x=pos, color='red')\n",
    "                    \n",
    "                    if df.index[start] <= line[1] <= df.index[end-1]:\n",
    "                        idx_before = df.index.get_loc(line[1], method='ffill')\n",
    "                        idx_after = df.index.get_loc(line[1], method='bfill')\n",
    "                        pos = (idx_before + idx_after) / 2 - start\n",
    "                        plt.axvline(x=pos, color='green')\n",
    "            \n",
    "            plt.title(f'Data from {subset.index[0]} to {subset.index[-1]}')\n",
    "            plt.show()\n",
    "\n",
    "    else:\n",
    "        for sub_df in df.resample(freq):\n",
    "            label, subset = sub_df\n",
    "            if not subset.empty:\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                subset[columns].plot(ax=plt.gca(), marker='.', linestyle='--', secondary_y=True)\n",
    "                if vertical_lines:\n",
    "                    for (line_idx, line) in enumerate(vertical_lines):\n",
    "                        line_plotted=False\n",
    "                        if subset.index[0] <= line[0] <= subset.index[-1]:\n",
    "                            plt.axvline(x=line[0], color='red')\n",
    "                            line_plotted=True\n",
    "                        if subset.index[0] <= line[1] <= subset.index[-1]:\n",
    "                            plt.axvline(x=line[1], color='green')\n",
    "                            line_plotted=True\n",
    "                        if line_plotted and len(line_text) == len(vertical_lines):\n",
    "                            print(f'line:{line_idx}, reason:{line_text[line_idx]}')\n",
    "                            \n",
    "                plt.title(f'Data from {subset.index[0]} to {subset.index[-1]}')\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_start_of_daily_block(date_series):\n",
    "    \"\"\"\n",
    "    Returns a boolean Series indicating if each date in the input Series is the \n",
    "    start of a new sequence of consecutive dates.\n",
    "\n",
    "    :param date_series: Pandas Series with datetime objects.\n",
    "    :return: Pandas Series of boolean values.\n",
    "    \"\"\"\n",
    "    # Ensure the Series is sorted\n",
    "    sorted_series = date_series.sort_values()\n",
    "\n",
    "    # Calculate the difference in days between each date and the previous date\n",
    "    day_diff = sorted_series.diff().dt.days\n",
    "\n",
    "    # Mark True where the difference is greater than 1 day, indicating a new sequence\n",
    "    is_start = day_diff > 1\n",
    "\n",
    "    # Handle the first element\n",
    "    if not is_start.empty:\n",
    "        is_start.iloc[0] = True\n",
    "\n",
    "    return is_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    df = df[(df['Extruder Pressure'] >= 0) & (df['Extruder Pressure'] < 50000)]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_machine_pauses(df, time_threshold=30, index=True):\n",
    "    if index:\n",
    "        time_diff = -1*(df.index.diff(-1).dt.total_seconds()/60)\n",
    "        machine_pauses = df[time_diff > time_threshold].index\n",
    "    else:\n",
    "        time_diff = -1*(df['Date and Time'].diff(-1).dt.total_seconds()/60)\n",
    "        machine_pauses = df[time_diff > time_threshold]['Date and Time']\n",
    "    \n",
    "    return machine_pauses\n",
    "\n",
    "def calculate_time_difference(df, time_threshold=30):\n",
    "    time_diff = -1*(df['Date and Time'].diff(-1).dt.total_seconds()/60)\n",
    "    #time_diff = (df['Date and Time'].shift(-1) - df['Date and Time']).dt.total_seconds()/60\n",
    "\n",
    "    return time_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_extruder_data(extruder_data):\n",
    "    \n",
    "    extruder_data = extruder_data.drop(extruder_data.index[0])\n",
    "    extruder_data = extruder_data.replace(\"<null>\", None)\n",
    "    \n",
    "    extruder_data = extruder_data.dropna()\n",
    "\n",
    "    # Convert the column to string type\n",
    "    for column in extruder_data.columns:\n",
    "        if column not in [\"Date and Time\", \"AnomalyScore\"]:\n",
    "            extruder_data[column] = extruder_data[column].astype(str)\n",
    "            #extruder_data[column] = extruder_data[column].str.replace(\"<null>\", None)\n",
    "            # Replace commas with an empty string\n",
    "            extruder_data[column] = extruder_data[column].str.replace(\",\", \"\")\n",
    "\n",
    "            # Convert the column back to numeric type, handling any conversion errors\n",
    "            extruder_data[column] = pd.to_numeric(extruder_data[column], errors=\"coerce\")\n",
    "            \n",
    "    extruder_data = extruder_data[(extruder_data['Extruder Pressure'] >= 0) & \\\n",
    "                              (extruder_data['Extruder Pressure'] < 50000)]\n",
    "\n",
    "    extruder_data['Date and Time'] = pd.to_datetime(extruder_data['Date and Time'])\n",
    "    \n",
    "    return extruder_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "columns_oi = ['Extruder Pressure']\n",
    "\n",
    "ex1_data = clean_extruder_data( pd.read_csv(\"ex1-data.csv\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ex1_data = ex1_data.groupby('Date and Time').mean()\n",
    "\n",
    "# resampling every 5 minutes instead of 1 minute\n",
    "\n",
    "ex1_resampled = ex1_data.resample('5T').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ex1_data['Date and Time'] = ex1_data.index\n",
    "ex1_pauses = get_machine_pauses(ex1_data, time_threshold=15, index=False)\n",
    "\n",
    "pauses = ex1_pauses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex1_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hours_since_last_pause(time, pauses):\n",
    "    return (time - pauses[pauses <= time].max()).total_seconds()/3600\n",
    "\n",
    "def hours_to_next_pause(time, pauses):\n",
    "    return (pauses[pauses >= time].min() - time).total_seconds()/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#from tqdm import tqdm\n",
    "\n",
    "ex1_data['hours_since_last_pause'] = ex1_data.index.to_series().apply(\n",
    "    lambda x : hours_since_last_pause(x, pauses)\n",
    ")\n",
    "ex1_data['hours_to_next_pause'] = ex1_data.index.to_series().apply(\n",
    "    lambda x : hours_to_next_pause(x, pauses)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extruder Pressure - for rolling\n",
    "# for lagged variables - Extruder Die Temp, Extruder Thrust\n",
    "\n",
    "#test = ex1_data.iloc[:1000][['Extruder Pressure']]\n",
    "\n",
    "\n",
    "for time_window in ['5T', '15T', '30T', '1H', '2H', '3H', '6H', '12H']:\n",
    "    if 'T' in time_window:\n",
    "        label_append = time_window.replace('T', 'min')\n",
    "    elif 'H' in time_window:\n",
    "        label_append = time_window.replace('H', 'hour')\n",
    "\n",
    "    col_label = 'pressure-' + label_append + '_avg'\n",
    "    ex1_data[col_label] = ex1_data['Extruder Pressure'].rolling(time_window).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_to_lag = ['Extruder Die Temp', 'Extruder Thrust']\n",
    "\n",
    "colname_map = {\n",
    "    'Extruder Die Temp' : 'die_temp-',\n",
    "    'Extruder Thrust' : 'thrust-',\n",
    "}\n",
    "#ex_num = 1\n",
    "\n",
    "#print(ex_num, ex1_data.shape)\n",
    "for time_window in ['5T', '15T', '1H', '3H']:\n",
    "    if 'T' in time_window:\n",
    "        label_append = time_window.replace('T', 'min')\n",
    "    elif 'H' in time_window:\n",
    "        label_append = time_window.replace('H', 'hour')\n",
    "    for lagvar in variables_to_lag:\n",
    "        col_label = colname_map[lagvar] + label_append + '_avg'\n",
    "        ex1_data[col_label] = \\\n",
    "            ex1_data[lagvar].rolling(time_window).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "def plot_entries_by_frequency(\n",
    "    datetime_series, \n",
    "    title='Number of entries by month',\n",
    "    freq='M',\n",
    "    kind='line',\n",
    "):\n",
    "    monthly_counts = datetime_series.groupby(pd.Grouper(freq=freq)).count()\n",
    "\n",
    "    monthly_counts.plot(kind=kind)\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('Number of Entries')\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "plot_entries_by_frequency(ex1_pauses, title='extruder 4 pauses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_entries_by_frequency(ex1_pauses, title='extruder 4 pauses', freq='W')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_entries_by_frequency(\n",
    "    ex1_pauses, \n",
    "    title='extruder 4 pauses', freq='D'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_datetime = pauses.min() - pd.Timedelta(days=7)\n",
    "max_datetime = pauses.max()\n",
    "\n",
    "time_mask = (ex1_data.index >= min_datetime) \\\n",
    "            & (ex1_data.index <= max_datetime)\n",
    "ex1_data = ex1_data[time_mask]\n",
    "\n",
    "redundancy_mask = (ex1_data['hours_since_last_pause'] >= 3) \\\n",
    "                  | (ex1_data['hours_to_next_pause'] >= 3)\n",
    "ex1_data = ex1_data[redundancy_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up classifier variables -\n",
    "# whether there is a pause within \n",
    "# {1 minute, 5 minutes, 10 minutes, 15 minutes, 30 minutes,\n",
    "#  1 hour, 2 hours, 3 hours, 6 hours, 12 hours, 24 hours}\n",
    "\n",
    "stop_target_to_hours_map = {\n",
    "#    '1min' : 1/60,\n",
    "    '5min' : 5/60,\n",
    "    '10min': 10/60,\n",
    "    '15min': 15/60,\n",
    "    '30min': 30/60,\n",
    "    '1hour': 1,\n",
    "    '2hour': 2,\n",
    "    '3hour': 3,\n",
    "    '6hour':6,\n",
    "    '12hour':12,\n",
    "    '24hour':24,\n",
    "}\n",
    "\n",
    "\n",
    "for window in stop_target_to_hours_map:\n",
    "    ex1_data[f'{window}_stop'] = \\\n",
    "        ex1_data['hours_to_next_pause'] < stop_target_to_hours_map[window]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_features = [s+ '_stop' for s in stop_target_to_hours_map.keys()]\n",
    "input_features = [\n",
    "    'Screw Speed Output',\n",
    "    'Screw Speed',\n",
    "    'Extruder Die Temp',\n",
    "    'Extruder Thrust',\n",
    "    'Feed Screw Current (Amps)',\n",
    "    'Discharge Conveyor Current (Amps)',\n",
    "    'Discharge Conveyor Speed (%)',\n",
    "    'pressure-5min_avg',\n",
    "    'pressure-15min_avg',\n",
    "    'pressure-30min_avg',\n",
    "    'pressure-1hour_avg',\n",
    "    'pressure-2hour_avg',\n",
    "    'pressure-3hour_avg',\n",
    "    'die_temp-5min_avg',\n",
    "    'thrust-5min_avg',\n",
    "    'die_temp-15min_avg',\n",
    "    'thrust-15min_avg',\n",
    "    'die_temp-1hour_avg',\n",
    "    'thrust-1hour_avg',\n",
    "    'die_temp-3hour_avg',\n",
    "    'thrust-3hour_avg',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "def balance_dataset(X, y, over_sample_ratio=0.1, under_sample_ratio=0.5):\n",
    "    \"\"\"\n",
    "    Balances the dataset by over-sampling the minority class and under-sampling the majority class.\n",
    "\n",
    "    :param X: Feature set.\n",
    "    :param y: Labels.\n",
    "    :param over_sample_ratio: Ratio of the number of samples in the minority class after resampling\n",
    "                              to the number of samples in the majority class before resampling.\n",
    "    :param under_sample_ratio: Ratio of the number of samples in the majority class after resampling\n",
    "                               to the number of samples in the minority class after over-sampling.\n",
    "\n",
    "    :return: Balanced features and labels.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the resampling strategy\n",
    "    over = SMOTE(sampling_strategy=over_sample_ratio)\n",
    "    under = RandomUnderSampler(sampling_strategy=under_sample_ratio)\n",
    "    steps = [('o', over), ('u', under)]\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "\n",
    "    # Transform the dataset\n",
    "    X_balanced, y_balanced = pipeline.fit_resample(X, y)\n",
    "\n",
    "    return X_balanced, y_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input = ex1_data[input_features]\n",
    "model_output = ex1_data[target_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import time\n",
    "\n",
    "# Load a dataset (Iris dataset as an example)\n",
    "#data = load_iris()\n",
    "X = model_input.values\n",
    "#y = model_output.values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the models to test\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Support Vector Machine': SVC(),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    'MLP' : MLPClassifier(hidden_layer_sizes=(16, 32), max_iter=1000)\n",
    "}\n",
    "\n",
    "# Dictionary to hold the results\n",
    "results = {}\n",
    "\n",
    "saved_processed_data = {}\n",
    "\n",
    "# Iterate over the models, fit, and evaluate them\n",
    "for targ in target_features:\n",
    "    if targ not in results:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        results[targ] = dict()\n",
    "    y = model_output[targ].values\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    n_true = np.sum((Y_train == 1))\n",
    "    n_false = np.sum((Y_train == 0))\n",
    "    print(f'original true samples: {n_true}, original false samples: {n_false}')\n",
    "    X_train, Y_train = balance_dataset(X_train, Y_train)\n",
    "    \n",
    "    saved_processed_data[targ] = (X_train, Y_train)\n",
    "    \n",
    "    n_true = np.sum((Y_train == 1))\n",
    "    n_false = np.sum((Y_train == 0))\n",
    "    print(f'balanced true samples: {n_true}, balanced false samples: {n_false}')\n",
    "    for name, model in models.items():\n",
    "        print()\n",
    "        print(f\"Current Time: {time.strftime('%H:%M:%S', time.localtime())}\")\n",
    "        print(f'results for target: {targ}, model: {model}')\n",
    "        model.fit(X_train, Y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        \n",
    "        # Compute the confusion matrix\n",
    "        conf_matrix = confusion_matrix(Y_test, predictions)\n",
    "\n",
    "        # Visualize the confusion matrix\n",
    "        #plt.figure(figsize=(10, 7))\n",
    "        #sns.heatmap(conf_matrix, annot=True, fmt='g')\n",
    "        #plt.xlabel('Predicted labels')\n",
    "        #plt.ylabel('True labels')\n",
    "        #plt.title('Confusion Matrix')\n",
    "        #plt.show()\n",
    "        accuracy = accuracy_score(Y_test, predictions)\n",
    "        cross_val = cross_val_score(model, X, y, cv=5)\n",
    "        results[targ][name] = {'Accuracy': accuracy, 'Cross-Val Mean': np.mean(cross_val),\n",
    "                              'Confusion_Matrix' : conf_matrix}\n",
    "        \n",
    "        \n",
    "        print(results[targ][name])\n",
    "        print('--------------------------------------')\n",
    "        \n",
    "        duration = time.time() - start_time\n",
    "        print(f\"Run time: {duration / 60:.2f} minutes\")\n",
    "        print(f\"Current Time: {time.strftime('%H:%M:%S', time.localtime())}\")\n",
    "        print('--------------------------------------')\n",
    "        \n",
    "    results_df = pd.DataFrame(results[targ]).T\n",
    "    #print(results_df)\n",
    "    print()\n",
    "    print()\n",
    "\n",
    "# Convert results to DataFrame for better visualization\n",
    "#results_df = pd.DataFrame(results).T\n",
    "#print(results_df)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
